{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Scrape FB for particular string using Selenium in PY\n",
    "\n",
    "Done By : Balaji Venktesh \n",
    "Dated   : 04/28/2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "\n",
    "# Importing Chrome Webdriver & surfing Facebook.com\n",
    "\n",
    "driver = webdriver.Chrome('C:\\\\Users\\\\arun\\\\Desktop\\\\DC Assignment\\\\DC Assignment\\\\chromedriver.exe') \n",
    "driver.get(\"http://www.facebook.com\")    #get URL's page source\n",
    "assert \"Facebook\" in driver.title   # confirm with assert() if 'facebook' is in page title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Providing Login Credentials  - Dynamic\n",
    "\n",
    "elem = driver.find_element_by_css_selector(\"#email\") \n",
    "elem.clear()    # first clear any pre-populated text in the input field\n",
    "elem.send_keys(input(\" \"))\n",
    "elem.send_keys(Keys.RETURN)\n",
    "    \n",
    "elem1 = driver.find_element_by_css_selector(\"#pass\")\n",
    "elem1.clear()    # first clear any pre-populated text in the input field\n",
    "elem1.send_keys(input(\" \"))    \n",
    "elem1.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Nike official page in Search bar\n",
    "\n",
    "elem2 = driver.find_element_by_css_selector(\"._1frb\")\n",
    "elem2.clear()    # first clear any pre-populated text in the input field\n",
    "elem2.send_keys('Nike')    \n",
    "elem2.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Beautifulsoup Library\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "linkElem = driver.find_element_by_link_text('Nike')\n",
    "type(linkElem)\n",
    "linkElem.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_photos = driver.find_element_by_link_text('Photos')\n",
    "type(link_photos)\n",
    "link_photos.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now load and scroll down nike page\n",
    "import time \n",
    "\n",
    "time.sleep(2)\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(2)\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\Lenovo\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding main container containing all loaded images\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "pagesrc = driver.page_source\n",
    "soup = BeautifulSoup(pagesrc)\n",
    "images = soup.find_all('div',{'class':'_2eec'})\n",
    "\n",
    "len(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "# Getting Total count of images loaded\n",
    "\n",
    "img = images[0].find_all('img', {\"class\":'img', 'height':200})\n",
    "count = len(img)\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get normal image for all the search string\n",
    "\n",
    "for i in range(count):\n",
    "    r = requests.get(img[i]['src'])\n",
    "    filename = 'D:\\\\DC Assignment' + '\\\\Image' + str(i) +  '.png'\n",
    "    with open(filename,'wb') as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "himg = images[0].find_all('a', {\"rel\":\"theater\"})\n",
    "himg[0]\n",
    "himg[0]['href']\n",
    "count  = len(himg)\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all HD image for the search string\n",
    "\n",
    "for i in range(count):\n",
    "    driver.get(himg[i]['href'] +'&theater')\n",
    "    time.sleep(1)\n",
    "    s = driver.page_source\n",
    "    sp = BeautifulSoup(s , \"lxml\")\n",
    "    a1  = sp.find_all('img', {'class':'spotlight'})\n",
    "    link = a1[0]['src']\n",
    "    r = requests.get(link) # create HTTP response object\n",
    "    filename = 'D:\\\\DC Assignment' + '\\\\HDImage' + str(i) + '.png'\n",
    "    with open(filename,'wb') as f:\n",
    "        f.write(r.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
